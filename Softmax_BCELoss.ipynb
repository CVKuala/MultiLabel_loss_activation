{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "'''for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "'''\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pylibjpeg pylibjpeg-libjpeg pylibjpeg-openjpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('../input/rsna-2022-cervical-spine-fracture-detection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets see how the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('../input/rsna-2022-cervical-spine-fracture-detection/train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Taking a small amount of the training data for quick experiment results.\n",
    "\n",
    "path='../input/rsna-2022-cervical-spine-fracture-detection/train_images'\n",
    "li=os.listdir('../input/rsna-2022-cervical-spine-fracture-detection/train_images')\n",
    "img_paths=[]\n",
    "for i in range(0,5):\n",
    "    img_paths.extend([os.path.join(path,li[i],j) for j in os.listdir(os.path.join(path,li[i]))])\n",
    "len(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing some important libraries\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Resnet Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, filters, subsample=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        if(subsample == True):\n",
    "            self.conv1 = nn.Conv2d(int(filters/2), filters, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(int(filters), filters, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            \n",
    "        self.bn1   = nn.BatchNorm2d(filters, track_running_stats=True)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(filters, filters, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(filters, track_running_stats=True)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.downsample = nn.AvgPool2d(kernel_size=1, stride=2)\n",
    "\n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(layer, nn.BatchNorm2d):\n",
    "                nn.init.constant_(layer.weight, 1)\n",
    "                nn.init.constant_(layer.bias, 0)        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.conv1(x)\n",
    "        z = self.bn1(z)\n",
    "        z = self.relu1(z)\n",
    "        \n",
    "        z = self.conv2(z)\n",
    "        z = self.bn2(z)\n",
    "\n",
    "        z = self.relu2(z)\n",
    "        \n",
    "        return z\n",
    "    \n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.convIn = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bnorm   = nn.BatchNorm2d(16, track_running_stats=True)\n",
    "        self.relu   = nn.ReLU()\n",
    "        \n",
    "        self.part1 = nn.ModuleList([BasicBlock(16, subsample=False), BasicBlock(16, subsample=False), BasicBlock(16, subsample=False)])\n",
    "\n",
    "        self.part2a = BasicBlock(32, subsample=True)\n",
    "        self.part2b = nn.ModuleList([BasicBlock(32, subsample=False), BasicBlock(32, subsample=False)])\n",
    "\n",
    "        self.part3a = BasicBlock(64, subsample=True)\n",
    "        self.part3b = nn.ModuleList([BasicBlock(64, subsample=False), BasicBlock(64, subsample=False)])\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.out   = nn.Linear(64, 8, bias=True)\n",
    "\n",
    "        self.Softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "        \n",
    "        # Initilise weights\n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.kaiming_normal(layer.weight)\n",
    "                layer.bias.data.zero_()      \n",
    "        \n",
    "        \n",
    "    def forward(self, x):     \n",
    "        x = self.convIn(x)\n",
    "        x = self.bnorm(x)\n",
    "        \n",
    "        x = self.relu(x)\n",
    "        for layer in self.part1: \n",
    "            x = layer(x)\n",
    "        \n",
    "        x = self.part2a(x)\n",
    "        for layer in self.part2b: \n",
    "            x = layer(x)\n",
    "        \n",
    "        x = self.part3a(x)\n",
    "        for layer in self.part3b: \n",
    "            x = layer(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.out(x)\n",
    "        return self.Softmax(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets define an instance of the Resnet Network and see whether it performs.\n",
    "\n",
    "import numpy as np\n",
    "a=ResNet(3)\n",
    "b=torch.randn([1,3,32,32])\n",
    "a(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Data Loading Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "import pydicom as dicom\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def load_dicom(path, size = 512):\n",
    "    \n",
    "    img=dicom.dcmread(path)\n",
    "    img.PhotometricInterpretation = 'YBR_FULL'\n",
    "    data=img.pixel_array\n",
    "    data=data-np.min(data)\n",
    "    if np.max(data) != 0:\n",
    "        data=data/np.max(data)\n",
    "    data=(data*255).astype(np.uint8)\n",
    "    #data=data.astype(np.uint8)\n",
    "    return cv2.cvtColor(cv2.resize(data,(32,32)), cv2.COLOR_GRAY2RGB).transpose([2,0,1]).astype(np.float32)\n",
    "\n",
    "class dcm_data(Dataset):\n",
    "    def __init__(self,image_paths,data):\n",
    "        self.image_paths=image_paths\n",
    "        self.data=data\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    def __getitem__(self,idx):\n",
    "        image_filepath=self.image_paths[idx]\n",
    "        image=load_dicom(image_filepath)\n",
    "        li_tensor=[]\n",
    "        li_tensor.append(int(self.data[self.data['StudyInstanceUID']==image_filepath.split('/')[-2]]['patient_overall'].values))\n",
    "        li_tensor.append(int(self.data[self.data['StudyInstanceUID']==image_filepath.split('/')[-2]]['C1'].values))\n",
    "        li_tensor.append(int(self.data[self.data['StudyInstanceUID']==image_filepath.split('/')[-2]]['C2'].values))\n",
    "        li_tensor.append(int(self.data[self.data['StudyInstanceUID']==image_filepath.split('/')[-2]]['C3'].values))\n",
    "        li_tensor.append(int(self.data[self.data['StudyInstanceUID']==image_filepath.split('/')[-2]]['C4'].values))\n",
    "        li_tensor.append(int(self.data[self.data['StudyInstanceUID']==image_filepath.split('/')[-2]]['C5'].values))\n",
    "        li_tensor.append(int(self.data[self.data['StudyInstanceUID']==image_filepath.split('/')[-2]]['C6'].values))\n",
    "        li_tensor.append(int(self.data[self.data['StudyInstanceUID']==image_filepath.split('/')[-2]]['C7'].values))\n",
    "        return image,torch.Tensor(li_tensor)\n",
    "\n",
    "\n",
    "def get_data_loaders(data_dir,data,\n",
    "                     batch_size,\n",
    "                     shuffle=True,\n",
    "                     num_workers=4,\n",
    "                     pin_memory=False):\n",
    "\n",
    "    \n",
    "\n",
    "    train_dataset=dcm_data(data_dir,data)\n",
    "    test_dataset=dcm_data(data_dir,data)\n",
    "    \n",
    "    # Create loader objects\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=shuffle,\n",
    "        num_workers=num_workers, pin_memory=pin_memory\n",
    "    )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=shuffle,\n",
    "        num_workers=num_workers, pin_memory=pin_memory\n",
    "    )\n",
    "          \n",
    "    return (train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Training and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def evaluate(model, data_loader, device):\n",
    "    \n",
    "    y_true = np.array([[]], dtype=np.int)\n",
    "    y_pred = np.array([[]], dtype=np.int)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            print(y_true)\n",
    "            print(labels.cpu())\n",
    "            y_true = np.concatenate((y_true, labels.cpu()))\n",
    "            y_pred = np.concatenate((y_pred, predicted.cpu()))\n",
    "    \n",
    "    error = np.sum(y_pred != y_true) / len(y_true)\n",
    "    return error\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, epochs, train_loader, test_loader, criterion, optimizer):\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    model.to(device)\n",
    "    \n",
    "    train_loss_li=[]\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        \n",
    "        model.train()\n",
    "        for i, data in enumerate(train_loader, 0):   # Do a batch iteration\n",
    "            \n",
    "            # get the inputs\n",
    "            inputs, labels = data   \n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # print average loss for last 3 mini-batches\n",
    "            total_loss += loss.item()\n",
    "            if i % 3 == 2:\n",
    "                print('Epoch : {}, Batch : {}, Loss : {}'.format((epoch + 1, i + 1, total_loss / 3)))\n",
    "                     \n",
    "                train_loss_li.append(total_loss/3)\n",
    "                total_loss = 0.0\n",
    "        \n",
    "        # Record metrics\n",
    "        model.eval()\n",
    "        train_loss = loss.item()    \n",
    "    \n",
    "    print('Finished Training with train_loss = {}'.format(train_loss))\n",
    "    return train_loss_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets use the data loader function and see if it outputs data. If it dosent work, restart the kernel and clear outputs. Run the notebook again and you will see that it works.\n",
    "\n",
    "train_ss,test_hhs=get_data_loaders(img_paths,data,128,shuffle=True,num_workers=4,pin_memory=False)\n",
    "data_load=iter(train_ss)\n",
    "images,labels=data_load.next()\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING PARAMETERS\n",
    "# -------------------------\n",
    "# This epoch can be changed, however for quick experiments, we kept the epoch value at 10.\n",
    "epochs = 10\n",
    "\n",
    "lr = 0.1\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0001 \n",
    "gamma = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN PLAIN NETs\n",
    "\n",
    "# n determines network size as described in paper\n",
    "# where total number of layers is (6*n)+2\n",
    "\n",
    "\n",
    "train_loader, test_loader = data_loaders(img_paths,data,\n",
    "                                                     512,\n",
    "                                                     shuffle=True,\n",
    "                                                     num_workers=4,\n",
    "                                                     pin_memory=True)\n",
    "\n",
    "model = ResNet()\n",
    "    \n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "loss_list=train_model(model, epochs, train_loader, test_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(loss_list), linestyle = 'dotted')\n",
    "plt.xlabel('epoch number')\n",
    "plt.ylabel('BCELoss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
